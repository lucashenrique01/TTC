{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6276ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def read_json_files_from_s3(bucket_name, prefix=None, max_files=None):\n",
    "    # Inicializa o recurso S3\n",
    "    s3r = boto3.resource('s3')\n",
    "\n",
    "    # Referência ao bucket S3\n",
    "    bucket = s3r.Bucket(bucket_name)\n",
    "\n",
    "    # Armazena os conteúdos dos arquivos JSON\n",
    "    json_files_contents = []\n",
    "\n",
    "    # Variável para contar o número de arquivos processados\n",
    "    file_count = 0\n",
    "\n",
    "    # Itera sobre os objetos no bucket, com o prefixo (se fornecido)\n",
    "    if prefix:\n",
    "        objects = bucket.objects.filter(Prefix=prefix)\n",
    "    else:\n",
    "        objects = bucket.objects.all()\n",
    "\n",
    "    # Processa os arquivos do bucket\n",
    "    for obj in objects:\n",
    "        # Verifica se o arquivo é JSON\n",
    "        if obj.key.endswith('.json'):\n",
    "            # Obtém o conteúdo do arquivo\n",
    "            file_content = obj.get()['Body'].read().decode('utf-8')\n",
    "\n",
    "            # Converte o conteúdo do JSON para um dicionário Python e armazena\n",
    "            json_data = json.loads(file_content)\n",
    "            json_files_contents.append(json_data)  # Armazena como dicionário\n",
    "\n",
    "            # Incrementa o contador de arquivos processados\n",
    "            file_count += 1\n",
    "\n",
    "            # Verifica se atingiu o limite de arquivos\n",
    "            if max_files and file_count >= max_files:\n",
    "                break\n",
    "\n",
    "    # Converte a lista de dicionários em um DataFrame\n",
    "    df = pd.DataFrame(json_files_contents)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8ac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "json_data = read_json_files_from_s3('match-info',max_files=10263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d56a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "\n",
    "# Itera por cada linha (partida)\n",
    "for index, row in json_data.iterrows():\n",
    "    if 'CLASSIC' in row['info']['gameMode']:\n",
    "#         print(row['info']['gameMode'])\n",
    "        match_data = {}\n",
    "\n",
    "        participants = row['info']['participants']\n",
    "#         print(participants)\n",
    "        teams = row['info']['teams']  \n",
    "        for i, participant in enumerate(participants):\n",
    "#             kills = participant['kills']\n",
    "#             deaths = participant['deaths']\n",
    "#             assists = participant['assists']        \n",
    "\n",
    "            \n",
    "            if 'challenges' in participant:\n",
    "                kda = participant['challenges']['kda']\n",
    "                gold_per_minute = participant['challenges']['goldPerMinute']\n",
    "            \n",
    "            vision_score = participant['visionScore']\n",
    "\n",
    "            match_data[f'player_{i+1}_kda'] = kda\n",
    "            match_data[f'player_{i+1}_gold_per_minute'] = gold_per_minute\n",
    "            match_data[f'player_{i+1}vision_score'] = vision_score\n",
    "\n",
    "        team_100 = next(team for team in teams if team['teamId'] == 100)\n",
    "        match_data['team_100_won'] = 1 if team_100['win'] else 0\n",
    "\n",
    "        processed_data.append(match_data)\n",
    "\n",
    "processed_df = pd.DataFrame(processed_data)\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "processed_df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Nome do bucket e chave (nome do arquivo no S3)\n",
    "bucket_name = 'match-dataset'\n",
    "s3_key = 'matchs.csv'\n",
    "\n",
    "# Salva o CSV no S3\n",
    "s3.put_object(Bucket=bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(\"CSV criado e salvo no S3 com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d1523b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import boto3\n",
    "import pandas as pd\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30eeba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ecbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Baixar o arquivo do S3\n",
    "csv_file = s3_client.get_object(Bucket='match-dataset', Key='matchs.csv')\n",
    "    \n",
    "# Ler o conteúdo do arquivo como uma string\n",
    "csv_content = csv_file['Body'].read().decode('utf-8')\n",
    "    \n",
    " # Converter para um DataFrame usando StringIO\n",
    "df = pd.read_csv(StringIO(csv_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a905c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['team_100_won'])\n",
    "y = df['team_100_won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "319e26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e87544e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o modelo\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc26b40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf53859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9349794238683128\n"
     ]
    }
   ],
   "source": [
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar a performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b08b99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nova_entrada = [\n",
    "[3.3988690476190477, 471.9657343736383, 0], \n",
    "[9, 414.0098336382496, 46.44444444444444], \n",
    "[5.111666666666667, 435.4742655669012, 0],\n",
    "[1, 363.4293092847436, 29.85], \n",
    "[1.3333333333333333, 416.8990610164101, 17.95], \n",
    "[2.8768831168831173, 533.3127612365831, 0], \n",
    "[3.0214814814814814, 322.24319249188727, 67.53333333333333],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c87326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 21 features, but RandomForestClassifier is expecting 30 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16535/1587020718.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fazer predição com o modelo treinado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredicao\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnova_entrada_unidimensional\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Predição para a nova entrada: {predicao}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \"\"\"\n\u001b[0;32m--> 808\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             raise ValueError(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 21 features, but RandomForestClassifier is expecting 30 features as input."
     ]
    }
   ],
   "source": [
    "# Transformar a entrada em um array unidimensional (como está no seu exemplo original)\n",
    "nova_entrada_unidimensional = [item for sublist in nova_entrada for item in sublist]\n",
    "\n",
    "# Fazer predição com o modelo treinado\n",
    "predicao = model.predict([nova_entrada_unidimensional])\n",
    "print(f'Predição para a nova entrada: {predicao}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fd8e7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de itens no bucket match-info: 10263\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Inicializa o cliente S3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def contar_itens_bucket(bucket_name):\n",
    "    # Lista todos os objetos no bucket\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "    \n",
    "    # Verifica se o bucket contém objetos\n",
    "    if 'Contents' not in response:\n",
    "        return 0\n",
    "    \n",
    "    # Conta os objetos\n",
    "    total_itens = len(response['Contents'])\n",
    "    \n",
    "    # Verifica se há mais páginas de objetos (paginado)\n",
    "    while response.get('IsTruncated'):  # Se o resultado estiver truncado, há mais objetos a serem recuperados\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name, ContinuationToken=response['NextContinuationToken'])\n",
    "        total_itens += len(response['Contents'])\n",
    "    \n",
    "    return total_itens\n",
    "\n",
    "# Nome do seu bucket S3\n",
    "bucket_name = 'match-info'\n",
    "\n",
    "# Exibe o total de itens\n",
    "total = contar_itens_bucket(bucket_name)\n",
    "print(f'Total de itens no bucket {bucket_name}: {total}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6402711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_random_forest2.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'modelo_random_forest2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccc3fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/ec2-user/modelo_random_forest3.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe8e65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.1.0 Requires-Python >=3.8; 1.1.1 Requires-Python >=3.8; 1.1.2 Requires-Python >=3.8; 1.1.3 Requires-Python >=3.8; 1.2.0 Requires-Python >=3.8; 1.2.0rc1 Requires-Python >=3.8; 1.2.1 Requires-Python >=3.8; 1.2.2 Requires-Python >=3.8; 1.3.0 Requires-Python >=3.8; 1.3.0rc1 Requires-Python >=3.8; 1.3.1 Requires-Python >=3.8; 1.3.2 Requires-Python >=3.8; 1.4.0 Requires-Python >=3.9; 1.4.0rc1 Requires-Python >=3.9; 1.4.1.post1 Requires-Python >=3.9; 1.4.2 Requires-Python >=3.9; 1.5.0 Requires-Python >=3.9; 1.5.0rc1 Requires-Python >=3.9; 1.5.1 Requires-Python >=3.9; 1.5.2 Requires-Python >=3.9\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-learn==1.5.2 (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21.0, 0.21.1, 0.21.2, 0.21.3, 0.22, 0.22.1, 0.22.2, 0.22.2.post1, 0.23.0, 0.23.1, 0.23.2, 0.24.0, 0.24.1, 0.24.2, 1.0, 1.0.1, 1.0.2)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for scikit-learn==1.5.2\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade scikit-learn==1.5.2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
